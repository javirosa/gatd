GATD: Get All The Data
======================

GATD is a cloud based system for managing and storing data streams. It was
born out of a need to handle data generated by disparate sensors with varying
data types, transmission protocols, and end-use goals.

GATD has three major design goals:

1. *Modularity*. GATD is a relatively loose collection of modules connected with
infinite length queues and a database layer. Each module is part of a certain
block of the system and many modules can exist for the same block. For example,
in the receiver block there is one module that listens for UDP packets and
another module that listens for HTTP requests. This allows GATD to be trivially
extended as functionality changes and new sensors come online.

2. *Flexibility*. GATD makes virtually no assumptions about the format, type,
or content of any data coming into the system. The exclusive requirement is
that a sensor must be able to identify its data stream to the system so it
can be processed properly. Each data stream has a custom parser that knows
how to make sense of its own data. The parser simply returns key,value pairs
with no restrictions on the key names or value types. GATD is designed to adapt
to the sensors, and not vice-versa.

3. *Timeliness*. GATD is specifically designed to support real-time streaming
applications where data comes in as it is generated and is sent out
to interested clients immediately. Every component is optimized for this
workflow. Additionally, all data is stored and can be retrieved and processed
later if necessary.


Structure
---------

diagram

The major blocks of GATD are as follows:

- *Receiver*. Responsible for accepting data from any sensors. Records
all relevant metadata with the data before passing it all to the formatter.

- *Formatter*. The formatter is a stateless block that converts raw data
from sensors into key,value pairs. The formatter calls the appropriate
parser to interpret the raw data before storing them in a database and
passing them on to any streamers.

- *Streamer*. The streamer block sends data to any interested clients.
Clients register a query with a streamer and any matching packets are sent
to the client.


Implementation
--------------

The current version of GATD is a research oriented implementation designed
for speed of development and experimentability rather than performance.
Most modules are written in Python, although due to the loose, modular approach
some are written in Node.js and C as well.

GATD uses RabbitMQ for the inter-module queues and MongoDB for data storage.

### Requirements

- Python 2.7.*
  - pika
  - IPy
  - pymongo
  - socketio
- MongoDB
- RabbitMQ
  - rabbitmq-c
- Node.js
  - npm
  - amqp
  - underscrore
  - query-engine
  - simple-ini
  - socket.io
  - forever


Installation
------------

1. Install [MongoDB](http://docs.mongodb.org/manual/installation/),
[RabbitMQ Server](http://www.rabbitmq.com/download.html), and
[Node.js](http://nodejs.org/download/).
2. Configure MongoDB using the template config file in the `mongo` folder.
TODO: elaborate
3. Configure RabbitMQ using the template config file in the `rabbitmq` folder.
TODO: elaborate
4. Set up Python environment
```bash
sudo pip2 install virtualenv
virtualenv .
source ./bin/activate
pip2 install pika IPy pymongo socketio
```
5. Install `rabbitmq-c` library for compiling the UDP receiver.
```bash
git clone git://github.com/alanxz/rabbitmq-c.git
cd rabbitmq-c
git submodule init
git submodule update
autoreconf -i
./configure
make
sudo make install
```
6. Install the Node.js dependencies
```bash
cd streamer
sudo npm install -g forever
npm install
```








